{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "IgdHnzSnzZs2"
   },
   "source": [
    "\n",
    "# Exercise 1.2\n",
    "## Classification of MNIST digits with a fully-connected neural network\n",
    "\n",
    "In this exercise we will classify [MNIST digits](https://en.wikipedia.org/wiki/MNIST_database) using a fully-connected neural network\n",
    "\n",
    "## Part 1: Using a Jupyter notebook on HPC\n",
    "If you are reading this, you probably already managed to open the Jupyter notebook on HPC -- if not, try to do that before doing the exercise.\n",
    "We start by importing the modules that we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "n6YTUAAlzZs5"
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with OpenSSL 1.0.2k-fips  26 Jan 2017. See: https://github.com/urllib3/urllib3/issues/2168",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnn\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfunctional\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mF\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorchvision\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdatasets\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mdatasets\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m \u001b[39mimport\u001b[39;00m DataLoader\n\u001b[1;32m      8\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorchvision\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtransforms\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtransforms\u001b[39;00m\n",
      "File \u001b[0;32m~/dlforcv/dl4cv/lib/python3.9/site-packages/torchvision/__init__.py:6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmodulefinder\u001b[39;00m \u001b[39mimport\u001b[39;00m Module\n\u001b[1;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchvision\u001b[39;00m \u001b[39mimport\u001b[39;00m datasets, io, models, ops, transforms, utils\n\u001b[1;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mextension\u001b[39;00m \u001b[39mimport\u001b[39;00m _HAS_OPS\n\u001b[1;32m     10\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/dlforcv/dl4cv/lib/python3.9/site-packages/torchvision/datasets/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_optical_flow\u001b[39;00m \u001b[39mimport\u001b[39;00m FlyingChairs, FlyingThings3D, HD1K, KittiFlow, Sintel\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_stereo_matching\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m      3\u001b[0m     CarlaStereo,\n\u001b[1;32m      4\u001b[0m     CREStereo,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m     SintelStereo,\n\u001b[1;32m     13\u001b[0m )\n\u001b[1;32m     14\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mcaltech\u001b[39;00m \u001b[39mimport\u001b[39;00m Caltech101, Caltech256\n",
      "File \u001b[0;32m~/dlforcv/dl4cv/lib/python3.9/site-packages/torchvision/datasets/_optical_flow.py:13\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mPIL\u001b[39;00m \u001b[39mimport\u001b[39;00m Image\n\u001b[1;32m     12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mio\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mimage\u001b[39;00m \u001b[39mimport\u001b[39;00m _read_png_16\n\u001b[0;32m---> 13\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m _read_pfm, verify_str_arg\n\u001b[1;32m     14\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mvision\u001b[39;00m \u001b[39mimport\u001b[39;00m VisionDataset\n\u001b[1;32m     17\u001b[0m T1 \u001b[39m=\u001b[39m Tuple[Image\u001b[39m.\u001b[39mImage, Image\u001b[39m.\u001b[39mImage, Optional[np\u001b[39m.\u001b[39mndarray], Optional[np\u001b[39m.\u001b[39mndarray]]\n",
      "File \u001b[0;32m~/dlforcv/dl4cv/lib/python3.9/site-packages/torchvision/datasets/utils.py:22\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39murllib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mparse\u001b[39;00m \u001b[39mimport\u001b[39;00m urlparse\n\u001b[1;32m     21\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mrequests\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_zoo\u001b[39;00m \u001b[39mimport\u001b[39;00m tqdm\n",
      "File \u001b[0;32m~/dlforcv/dl4cv/lib/python3.9/site-packages/requests/__init__.py:43\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[39mRequests HTTP Library\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[39m~~~~~~~~~~~~~~~~~~~~~\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[39m:license: Apache 2.0, see LICENSE for more details.\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mwarnings\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39murllib3\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mexceptions\u001b[39;00m \u001b[39mimport\u001b[39;00m RequestsDependencyWarning\n\u001b[1;32m     47\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/dlforcv/dl4cv/lib/python3.9/site-packages/urllib3/__init__.py:38\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     33\u001b[0m     \u001b[39m# fmt: off\u001b[39;00m\n\u001b[1;32m     34\u001b[0m     \u001b[39mif\u001b[39;00m (\n\u001b[1;32m     35\u001b[0m         \u001b[39mnot\u001b[39;00m ssl\u001b[39m.\u001b[39mOPENSSL_VERSION\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39mOpenSSL \u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     36\u001b[0m         \u001b[39mor\u001b[39;00m ssl\u001b[39m.\u001b[39mOPENSSL_VERSION_INFO \u001b[39m<\u001b[39m (\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[1;32m     37\u001b[0m     ):  \u001b[39m# Defensive:\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\n\u001b[1;32m     39\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39murllib3 v2.0 only supports OpenSSL 1.1.1+, currently \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     40\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mthe \u001b[39m\u001b[39m'\u001b[39m\u001b[39mssl\u001b[39m\u001b[39m'\u001b[39m\u001b[39m module is compiled with \u001b[39m\u001b[39m{\u001b[39;00mssl\u001b[39m.\u001b[39mOPENSSL_VERSION\u001b[39m}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     41\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mSee: https://github.com/urllib3/urllib3/issues/2168\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     42\u001b[0m         )\n\u001b[1;32m     43\u001b[0m     \u001b[39m# fmt: on\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \n\u001b[1;32m     45\u001b[0m \u001b[39m# === NOTE TO REPACKAGERS AND VENDORS ===\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[39m# Please delete this block, this logic is only\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[39m# for urllib3 being distributed via PyPI.\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[39m# See: https://github.com/urllib3/urllib3/issues/2680\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[0;31mImportError\u001b[0m: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with OpenSSL 1.0.2k-fips  26 Jan 2017. See: https://github.com/urllib3/urllib3/issues/2168"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "sOeRq_xHzZtC"
   },
   "source": [
    "We check that we have a GPU available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eRKroSgizZtC"
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"The code will run on GPU.\")\n",
    "else:\n",
    "    print(\"The code will run on CPU. Go to Edit->Notebook Settings and choose GPU as the hardware accelerator\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Hf5kG-RszZtG"
   },
   "source": [
    "The MNIST dataset is a built-in dataset in PyTorch (it is a very common dataset to test algorithms on). \n",
    "\n",
    "We import it, and set our minibatch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lzZHxNsgzZtH"
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "trainset = datasets.MNIST('./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "testset = datasets.MNIST('./data', train=False, download=True, transform=transforms.ToTensor())\n",
    "test_loader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "7xoF9GRL25jq"
   },
   "source": [
    "First, we plot the images to get an idea of what data we're working with. MNIST images are $28\\times28$ images of handwritten digits (0-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mjeITqYf1itt"
   },
   "outputs": [],
   "source": [
    "images, labels = next(iter(train_loader))\n",
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "for i in range(21):\n",
    "    plt.subplot(5,7,i+1)\n",
    "    plt.imshow(images[i].numpy()[0], 'gray')\n",
    "    plt.title(labels[i].item())\n",
    "    plt.axis('off')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "hGuvRy0zzZtP"
   },
   "source": [
    "You should implement a fully-connected network to classify the digits. It should contain 1 hidden layer with 100 units. Don't forget the ReLU activation function after the hidden layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kkWvoY__zZtQ"
   },
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.fully_connected1 = nn.Sequential(\n",
    "            ...,\n",
    "            ...,\n",
    "            )\n",
    "        \n",
    "        self.fully_connected2 = nn.Sequential(\n",
    "            nn.Linear(100,10),\n",
    "            nn.Softmax(dim = 1)\n",
    "            )\n",
    "        \n",
    "    def forward(self, x):\n",
    "      #reshaping x so it becomes flat, except for the first dimension (which is the minibatch)\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = self.fully_connected1(x)\n",
    "        x = self.fully_connected2(x)\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "_i2qWBsNzZtU"
   },
   "source": [
    "We instantiate a copy of our network and transfer it to the GPU if it's available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VJVToX8hzZtV"
   },
   "outputs": [],
   "source": [
    "model = Network()\n",
    "model.to(device)\n",
    "#Initialize the optimer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Ky-KOYBA3i4R"
   },
   "source": [
    "We train the network for five epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YEQU9cIVzZth"
   },
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "\n",
    "for epoch in tqdm(range(num_epochs), unit='epoch'):\n",
    "    #For each epoch\n",
    "    train_correct = 0\n",
    "    for minibatch_no, (data, target) in tqdm(enumerate(train_loader), total=len(train_loader)):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        #Zero the gradients computed for each weight\n",
    "        optimizer.zero_grad()\n",
    "        #Forward pass your image through the network\n",
    "        output = model(data)\n",
    "        #Compute the loss\n",
    "        loss = F.nll_loss(torch.log(output), target)\n",
    "        #Backward pass through the network\n",
    "        loss.backward()\n",
    "        #Update the weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        #Compute how many were correctly classified\n",
    "        predicted = output.argmax(1)\n",
    "        train_correct += (target==predicted).sum().cpu().item()\n",
    "    #Comput the test accuracy\n",
    "    test_correct = 0\n",
    "    for data, target in test_loader:\n",
    "        data = data.to(device)\n",
    "        with torch.no_grad():\n",
    "            output = model(data)\n",
    "        predicted = output.argmax(1).cpu()\n",
    "        test_correct += (target==predicted).sum().item()\n",
    "    train_acc = train_correct/len(trainset)\n",
    "    test_acc = test_correct/len(testset)\n",
    "    print(\"Accuracy train: {train:.1f}%\\t test: {test:.1f}%\".format(test=100*test_acc, train=100*train_acc))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Rq---Q6xzZtl"
   },
   "source": [
    "You should now have a model that has about 96% accuracy on the test set.\n",
    "Try to get an even better accuracy. You can\n",
    "* Change the number of hidden layers\n",
    "* Change the number of units in the hidden layers\n",
    "* Try changing the learning rate by factors of 10. What happens if it is too high or too low?\n",
    "* Try using sigmoid instead of ReLU activation. What happens?\n",
    "\n",
    "How large accuracy can you get?\n",
    "\n",
    "Try showing the classification output (probabilities) from the model alongside the ground truth.\n",
    "\n",
    "* Which are classified correctly/incorrectly? \n",
    "* If it's incorrect, what is the second most likely class?\n",
    "* Do the misclassifications you see make sense? Why/why not?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Running code in the terminal\n",
    "Next, implement the classifier from this Jupyter notebook in a (reasonably clean) python script and train it from a terminal on HPC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Exercise 1.1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
