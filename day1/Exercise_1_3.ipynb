{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "oW29Y96P5LrX"
   },
   "source": [
    "# Exercise 1.3\n",
    "## Classification of MNIST digits with a convolutional neural network\n",
    "\n",
    "In this exercise we will classify MNIST digits again, but this time we will use a convolutional neural network (CNN).\n",
    "\n",
    "## Part 1: Using Jupyter notebook\n",
    "The exercise is written throughout this Jupyter notebook, and you should feel free to solve it within the notebook -- but you should also feel free to directly implement it as a script and run it in the terminal from the start (this will be part 2).\n",
    "\n",
    "First we import the modules we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "jz2q4lHP5LrY"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Kr5H-aka5Lrc"
   },
   "source": [
    "We check that this script has a GPU available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "1Uvbi4IX5Lrc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The code will run on GPU.\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"The code will run on GPU.\")\n",
    "else:\n",
    "    print(\"The code will run on CPU. Go to Edit->Notebook Settings and choose GPU as the hardware accelerator\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "h9w4bzfX5Lrh"
   },
   "source": [
    "We import the MNIST dataset, which is built into pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "yF0nU9c85Lri"
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "trans = transforms.Compose([transforms.ToTensor(), transforms.RandomRotation(1)])\n",
    "trainset = datasets.MNIST('./data', train=True, download=True, transform=trans)\n",
    "train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "testset = datasets.MNIST('./data', train=False, download=True, transform=transforms.ToTensor())\n",
    "test_loader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "8PnRF_Ev5Lrm"
   },
   "source": [
    "You should implement a network to classify MNIST digits. \n",
    "The network should consist of two parts, a part with convolutions and one with fully connected layers.\n",
    "The convolutional part we will call `convolutional`, and it should contain the follwing:\n",
    "* two convolutional layers with 8 features\n",
    "* a $2\\times2$ max pooling layer\n",
    "* two convolutional layers with 16 features\n",
    "\n",
    "The convolutions should be $3\\times 3$, and should not change the size of the output. What does this mean that the stride and padding should be?\n",
    "\n",
    "For example check the documentation of the `nn` module https://pytorch.org/docs/stable/nn.html\n",
    "\n",
    "**Remember**: There's a specific type of layer that you should always have after a convolution or a fully connected layer. What is this type of layer called?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "HqJTyYy35Lrn"
   },
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.convolutional = nn.Sequential(\n",
    "                nn.Conv2d(1, 8, kernel_size=3, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(8, 16, kernel_size=3, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(2, 2),\n",
    "                nn.ReLU())\n",
    "\n",
    "        self.fully_connected = nn.Sequential(\n",
    "                nn.Linear(14*14*16, 500),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.5),\n",
    "                nn.Linear(500, 10),\n",
    "                nn.Softmax(dim=1))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.convolutional(x)\n",
    "        #reshape x so it becomes flat, except for the first dimension (which is the minibatch)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fully_connected(x)\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "EKI3L0rh5Lrq"
   },
   "source": [
    "We instantiate a copy of our network, transfer it to the GPU if it's available.\n",
    "We also check if the dimensions of our network match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "mD7N5AZA5Lrr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the output from the convolutional part torch.Size([64, 16, 14, 14])\n"
     ]
    }
   ],
   "source": [
    "model = Network()\n",
    "model.to(device)\n",
    "#Initialize the optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "#Get the first minibatch\n",
    "data = next(iter(train_loader))[0].cuda()\n",
    "#Try running the model on a minibatch\n",
    "print('Shape of the output from the convolutional part', model.convolutional(data).shape)\n",
    "model(data); #if this runs the model dimensions fit"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "GCjfL-y_5Lru"
   },
   "source": [
    "We train this network for five epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "XyuQgHmE5Lrv",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3367d80d7158459295f67b0d910184bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40de4ba487e148a2b65ca19d42b8028a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train: 81.4%\t test: 95.6%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a00c887fe6c844b29d0485fd92d3be83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train: 94.2%\t test: 97.6%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c53f0861632043eba701748bebabb703",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train: 95.9%\t test: 97.8%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9882a7cd9244415f915d5a351f3d4aad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train: 96.6%\t test: 98.4%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bbe8fec14624a49b2d4d5fd07a25b86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train: 97.0%\t test: 98.5%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9db0874a17ba44f7b82d8beb709253b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train: 97.4%\t test: 98.6%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b528dca7ccb4ffabea91f8e62e94963",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train: 42.2%\t test: 9.8%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e3b1e4e1e774174a54482c157974d72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train: 9.9%\t test: 9.8%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "850e03cbead9440c993b38e999de49fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train: 9.9%\t test: 9.8%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c33a3d5b8cea485bbf026684c07ebd4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "for epoch in tqdm(range(num_epochs), unit='epoch'):\n",
    "    #For each epoch\n",
    "    train_correct = 0\n",
    "    model.train()\n",
    "    for minibatch_no, (data, target) in tqdm(enumerate(train_loader), total=len(train_loader)):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        #Zero the gradients computed for each weight\n",
    "        optimizer.zero_grad()\n",
    "        #Forward pass your image through the network\n",
    "        output = model(data)\n",
    "        #Compute the loss\n",
    "        loss = F.nll_loss(torch.log(output), target)\n",
    "        #Backward pass through the network\n",
    "        loss.backward()\n",
    "        #Update the weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        #Compute how many were correctly classified\n",
    "        predicted = output.argmax(1)\n",
    "        train_correct += (target==predicted).sum().cpu().item()\n",
    "    #Comput the test accuracy\n",
    "    test_correct = 0\n",
    "    model.eval()\n",
    "    for data, target in test_loader:\n",
    "        data = data.to(device)\n",
    "        with torch.no_grad():\n",
    "            output = model(data)\n",
    "        predicted = output.argmax(1).cpu()\n",
    "        test_correct += (target==predicted).sum().item()\n",
    "    train_acc = train_correct/len(trainset)\n",
    "    test_acc = test_correct/len(testset)\n",
    "    print(\"Accuracy train: {train:.1f}%\\t test: {test:.1f}%\".format(test=100*test_acc, train=100*train_acc))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "zoEC9oDH5Lr0"
   },
   "source": [
    "Hopefully you now have a model that's able to achieve decent performance on MNIST.\n",
    "It should have around 97.5% accuracy on the test set after the first epoch.\n",
    "\n",
    "* Why is the accuracy on the training set higher than on the test set? (recall from machine learning)\n",
    "\n",
    "* Why does it have higher accuracy on the test set than the training set after the first epoch?\n",
    "\n",
    "   hint: it's related to how the train accuracy is computed\n",
    "\n",
    "### Data augmentation\n",
    " * Add random rotations to the MNIST digits during training (you have to go back and modify the dataloader)\n",
    " \n",
    "  hint: you can use `transforms.RandomRotation` \n",
    "  \n",
    "  hint: you can combine multiple transforms into one with `transforms.Compose`\n",
    "\n",
    "How does this affect your training and testing loss?\n",
    "\n",
    " * Try plotting some of the augmented images, to visually confirm what your augmentation is doing.\n",
    "\n",
    " * Try adding another type of data augmentation."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "3Uf7eO8P5Lr1"
   },
   "source": [
    "### Explore the model\n",
    "What has the model learned? You can access all the weights in the model with `model.parameters()`. Here we just print the shape.\n",
    " - Try showing images of the filters in the first layer. \n",
    " - Can you from the dimensions of the weights alone identify which layer it is in our model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-lkTsfgo5Lr1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([8, 1, 3, 3]),\n",
       " torch.Size([8]),\n",
       " torch.Size([16, 8, 3, 3]),\n",
       " torch.Size([16]),\n",
       " torch.Size([500, 3136]),\n",
       " torch.Size([500]),\n",
       " torch.Size([10, 500]),\n",
       " torch.Size([10])]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w.shape for w in model.parameters()]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "t0Fyc1SG5Lr4"
   },
   "source": [
    "### Dropout\n",
    " * Try adding dropout to your model.\n",
    " \n",
    "You can add it between the convolutional layers and or in the fully connected part.\n",
    "\n",
    "Remember to call `net.train()` and `net.eval()` to change the model from test to training state, so it knows when you want it to apply dropout."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Solving the exercise with a script to be run in the terminal\n",
    "Next, implement your code in a (reasonably clean) python script and run it from a terminal on HPC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Exercise 1.2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
