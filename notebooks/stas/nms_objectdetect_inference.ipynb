{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import glob\n",
    "from hydra import compose, initialize\n",
    "import hydra\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import yaml\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "from dl4cv.utils.utils import set_seed\n",
    "from dl4cv.lightning_classes.plmodel import LitODModel\n",
    "from dl4cv.datasets import build_taco \n",
    "from dl4cv.datasets.taco_data import taco_val_test_collate_fn\n",
    "from tqdm import tqdm\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hydra.core.global_hydra.GlobalHydra.instance().clear()\n",
    "initialize(config_path=\"./configs\")\n",
    "inference_cfg = compose(config_name=\"config_taco_training\")\n",
    "inference_cfg[\"inference\"][\"run_name\"] = 'Resnet50_Whale'\n",
    "inference_cfg[\"inference\"][\"device\"] = 'cuda:0'\n",
    "path = f\"outputs/{inference_cfg.inference.run_name}/.hydra/config.yaml\"\n",
    "with open(path) as cfg:\n",
    "    cfg_yaml = yaml.safe_load(cfg)\n",
    "cfg_yaml[\"inference\"] = inference_cfg[\"inference\"]\n",
    "cfg_yaml[\"datamodule\"][\"test\"][\"params\"][\"num_to_return\"] = 100\n",
    "cfg = OmegaConf.create(cfg_yaml)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(cfg: DictConfig) -> None:\n",
    "    \"\"\"\n",
    "    Run pytorch-lightning model inference\n",
    "    Args:\n",
    "        cfg: hydra config\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    set_seed(cfg.training.seed)\n",
    "\n",
    "    device = torch.device(cfg.inference.device)\n",
    "\n",
    "    model_names = glob.glob(f\"outputs/{cfg.inference.run_name}/saved_models/*.ckpt\")\n",
    "    _, _, test_set = build_taco(cfg)\n",
    "    # Dirty trick to get the ground truth boxes\n",
    "    loader = torch.utils.data.DataLoader(\n",
    "        test_set,\n",
    "        collate_fn=taco_val_test_collate_fn,\n",
    "        batch_size=1,\n",
    "        num_workers=1,\n",
    "        shuffle=False,\n",
    "    )\n",
    "    lit_model = LitODModel.load_from_checkpoint(checkpoint_path=model_names[0], cfg=cfg)\n",
    "    lit_model.to(device)\n",
    "    predictions = []\n",
    "    for batch in tqdm(loader):\n",
    "        # move batch elements to device\n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        predictions.append(\n",
    "            lit_model.nms_on_image(\n",
    "                batch,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return predictions\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [02:30<00:00,  1.66it/s]\n"
     ]
    }
   ],
   "source": [
    "predictions = main(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "print(len(predictions[6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from PIL import Image, ExifTags\n",
    "from dl4cv.utils.object_detect_utils import get_iou, fix_orientation, CAT_MAPPING\n",
    "\n",
    "def _get_ground_truth_boxes():\n",
    "    file = '/dtu/blackhole/0f/160495/s210527/taco/test/test_annotations.json'\n",
    "    with open(file, \"r\") as f:\n",
    "        dataset = json.load(f)\n",
    "    \n",
    "    target_size = (1280, 720)\n",
    "    BACKGROUND_LABEL = -1\n",
    "    label_map = CAT_MAPPING\n",
    "\n",
    "    for orientation in ExifTags.TAGS.keys():\n",
    "        if ExifTags.TAGS[orientation] == \"Orientation\":\n",
    "            break\n",
    "    dataset_root_path=\"/dtu/datasets1/02514/data_wastedetection\"\n",
    "    \n",
    "    out_gt = {}\n",
    "    for i in dataset[\"images\"]:\n",
    "        print(i)\n",
    "        annot_boxes = [\n",
    "            annotation[\"bbox\"]\n",
    "            for annotation in dataset[\"annotations\"]\n",
    "            if annotation[\"image_id\"] == i['image_id']\n",
    "        ]\n",
    "        annots_labels = [\n",
    "            label_map[annotation[\"category_id\"]]\n",
    "            for annotation in dataset[\"annotations\"]\n",
    "            if annotation[\"image_id\"] == i['image_id']\n",
    "        ]\n",
    "        filename = os.path.join(dataset_root_path, i[\"file_name\"])\n",
    "        \n",
    "        I = fix_orientation(filename, orientation)\n",
    "        image = cv2.cvtColor(np.array(I), cv2.COLOR_RGB2BGR)\n",
    "        scale_factor = (\n",
    "            image.shape[0] / target_size[1],  # height\n",
    "            image.shape[1] / target_size[0],  # width\n",
    "        )\n",
    "        image = cv2.resize(\n",
    "            image, (target_size[0], target_size[1]), interpolation=cv2.INTER_AREA\n",
    "        )\n",
    "        gtvalues = []\n",
    "        for a_index, annot in enumerate(annot_boxes):\n",
    "            x1 = int(annot[0] / scale_factor[1])\n",
    "            y1 = int(annot[1] / scale_factor[0])\n",
    "            x2 = int(annot[0] / scale_factor[1] + annot[2] / scale_factor[1])\n",
    "            y2 = int(annot[1] / scale_factor[0] + annot[3] / scale_factor[0])\n",
    "            assert (\n",
    "                y2 <= target_size[1] and y1 <= target_size[1]\n",
    "            ), f\"y2 = {y2} and y1 = {y1} for gt of image {filename} with resized dims {image.shape}\"\n",
    "            assert (\n",
    "                x2 <= target_size[0] and x1 <= target_size[0]\n",
    "            ), f\"x2 = {x2} and x1 = {x1} for gt of image {filename} with resized dims {image.shape}\"\n",
    "            gtvalues.append(\n",
    "                {\n",
    "                    \"x1\": x1,\n",
    "                    \"x2\": x2,\n",
    "                    \"y1\": y1,\n",
    "                    \"y2\": y2,\n",
    "                    \"label\": annots_labels[a_index],\n",
    "                }\n",
    "            )\n",
    "        out_gt[i['image_id']] = gtvalues\n",
    "\n",
    "    return out_gt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'image_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m gt_boxes \u001b[39m=\u001b[39m _get_ground_truth_boxes()\n",
      "Cell \u001b[0;32mIn[6], line 25\u001b[0m, in \u001b[0;36m_get_ground_truth_boxes\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m out_gt \u001b[39m=\u001b[39m {}\n\u001b[1;32m     24\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m dataset[\u001b[39m\"\u001b[39m\u001b[39mimages\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m---> 25\u001b[0m     annot_boxes \u001b[39m=\u001b[39m [\n\u001b[1;32m     26\u001b[0m         annotation[\u001b[39m\"\u001b[39m\u001b[39mbbox\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m     27\u001b[0m         \u001b[39mfor\u001b[39;00m annotation \u001b[39min\u001b[39;00m dataset[\u001b[39m\"\u001b[39m\u001b[39mannotations\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m     28\u001b[0m         \u001b[39mif\u001b[39;00m annotation[\u001b[39m\"\u001b[39m\u001b[39mimage_id\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m==\u001b[39m i[\u001b[39m'\u001b[39m\u001b[39mimage_id\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     29\u001b[0m     ]\n\u001b[1;32m     30\u001b[0m     annots_labels \u001b[39m=\u001b[39m [\n\u001b[1;32m     31\u001b[0m         label_map[annotation[\u001b[39m\"\u001b[39m\u001b[39mcategory_id\u001b[39m\u001b[39m\"\u001b[39m]]\n\u001b[1;32m     32\u001b[0m         \u001b[39mfor\u001b[39;00m annotation \u001b[39min\u001b[39;00m dataset[\u001b[39m\"\u001b[39m\u001b[39mannotations\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m     33\u001b[0m         \u001b[39mif\u001b[39;00m annotation[\u001b[39m\"\u001b[39m\u001b[39mimage_id\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m==\u001b[39m i[\u001b[39m'\u001b[39m\u001b[39mimage_id\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     34\u001b[0m     ]\n\u001b[1;32m     35\u001b[0m     filename \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(dataset_root_path, i[\u001b[39m\"\u001b[39m\u001b[39mfile_name\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "Cell \u001b[0;32mIn[6], line 28\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     23\u001b[0m out_gt \u001b[39m=\u001b[39m {}\n\u001b[1;32m     24\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m dataset[\u001b[39m\"\u001b[39m\u001b[39mimages\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m     25\u001b[0m     annot_boxes \u001b[39m=\u001b[39m [\n\u001b[1;32m     26\u001b[0m         annotation[\u001b[39m\"\u001b[39m\u001b[39mbbox\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m     27\u001b[0m         \u001b[39mfor\u001b[39;00m annotation \u001b[39min\u001b[39;00m dataset[\u001b[39m\"\u001b[39m\u001b[39mannotations\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m---> 28\u001b[0m         \u001b[39mif\u001b[39;00m annotation[\u001b[39m\"\u001b[39m\u001b[39mimage_id\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m==\u001b[39m i[\u001b[39m'\u001b[39;49m\u001b[39mimage_id\u001b[39;49m\u001b[39m'\u001b[39;49m]\n\u001b[1;32m     29\u001b[0m     ]\n\u001b[1;32m     30\u001b[0m     annots_labels \u001b[39m=\u001b[39m [\n\u001b[1;32m     31\u001b[0m         label_map[annotation[\u001b[39m\"\u001b[39m\u001b[39mcategory_id\u001b[39m\u001b[39m\"\u001b[39m]]\n\u001b[1;32m     32\u001b[0m         \u001b[39mfor\u001b[39;00m annotation \u001b[39min\u001b[39;00m dataset[\u001b[39m\"\u001b[39m\u001b[39mannotations\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m     33\u001b[0m         \u001b[39mif\u001b[39;00m annotation[\u001b[39m\"\u001b[39m\u001b[39mimage_id\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m==\u001b[39m i[\u001b[39m'\u001b[39m\u001b[39mimage_id\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     34\u001b[0m     ]\n\u001b[1;32m     35\u001b[0m     filename \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(dataset_root_path, i[\u001b[39m\"\u001b[39m\u001b[39mfile_name\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "\u001b[0;31mKeyError\u001b[0m: 'image_id'"
     ]
    }
   ],
   "source": [
    "gt_boxes = _get_ground_truth_boxes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'bbox': {'x1': tensor(723, device='cuda:0', dtype=torch.int32),\n",
       "   'y1': tensor(158, device='cuda:0', dtype=torch.int32),\n",
       "   'x2': tensor(958, device='cuda:0', dtype=torch.int32),\n",
       "   'y2': tensor(695, device='cuda:0', dtype=torch.int32)},\n",
       "  'conf': 0.9853888154029846,\n",
       "  'pred_class': 20,\n",
       "  'true_class': 20,\n",
       "  'image_id': 217},\n",
       " {'bbox': {'x1': tensor(188, device='cuda:0', dtype=torch.int32),\n",
       "   'y1': tensor(99, device='cuda:0', dtype=torch.int32),\n",
       "   'x2': tensor(548, device='cuda:0', dtype=torch.int32),\n",
       "   'y2': tensor(395, device='cuda:0', dtype=torch.int32)},\n",
       "  'conf': 0.9745054244995117,\n",
       "  'pred_class': 13,\n",
       "  'true_class': 13,\n",
       "  'image_id': 217},\n",
       " {'bbox': {'x1': tensor(224, device='cuda:0', dtype=torch.int32),\n",
       "   'y1': tensor(261, device='cuda:0', dtype=torch.int32),\n",
       "   'x2': tensor(236, device='cuda:0', dtype=torch.int32),\n",
       "   'y2': tensor(271, device='cuda:0', dtype=torch.int32)},\n",
       "  'conf': 0.827072262763977,\n",
       "  'pred_class': 14,\n",
       "  'true_class': 28,\n",
       "  'image_id': 217},\n",
       " {'bbox': {'x1': tensor(181, device='cuda:0', dtype=torch.int32),\n",
       "   'y1': tensor(132, device='cuda:0', dtype=torch.int32),\n",
       "   'x2': tensor(193, device='cuda:0', dtype=torch.int32),\n",
       "   'y2': tensor(156, device='cuda:0', dtype=torch.int32)},\n",
       "  'conf': 0.577078640460968,\n",
       "  'pred_class': 16,\n",
       "  'true_class': 28,\n",
       "  'image_id': 217},\n",
       " {'bbox': {'x1': tensor(891, device='cuda:0', dtype=torch.int32),\n",
       "   'y1': tensor(114, device='cuda:0', dtype=torch.int32),\n",
       "   'x2': tensor(989, device='cuda:0', dtype=torch.int32),\n",
       "   'y2': tensor(519, device='cuda:0', dtype=torch.int32)},\n",
       "  'conf': 0.5749379992485046,\n",
       "  'pred_class': 20,\n",
       "  'true_class': 28,\n",
       "  'image_id': 217},\n",
       " {'bbox': {'x1': tensor(497, device='cuda:0', dtype=torch.int32),\n",
       "   'y1': tensor(119, device='cuda:0', dtype=torch.int32),\n",
       "   'x2': tensor(593, device='cuda:0', dtype=torch.int32),\n",
       "   'y2': tensor(393, device='cuda:0', dtype=torch.int32)},\n",
       "  'conf': 0.5112253427505493,\n",
       "  'pred_class': 13,\n",
       "  'true_class': 28,\n",
       "  'image_id': 217},\n",
       " {'bbox': {'x1': tensor(814, device='cuda:0', dtype=torch.int32),\n",
       "   'y1': tensor(287, device='cuda:0', dtype=torch.int32),\n",
       "   'x2': tensor(937, device='cuda:0', dtype=torch.int32),\n",
       "   'y2': tensor(550, device='cuda:0', dtype=torch.int32)},\n",
       "  'conf': 0.4988349974155426,\n",
       "  'pred_class': 20,\n",
       "  'true_class': 28,\n",
       "  'image_id': 217},\n",
       " {'bbox': {'x1': tensor(232, device='cuda:0', dtype=torch.int32),\n",
       "   'y1': tensor(102, device='cuda:0', dtype=torch.int32),\n",
       "   'x2': tensor(521, device='cuda:0', dtype=torch.int32),\n",
       "   'y2': tensor(161, device='cuda:0', dtype=torch.int32)},\n",
       "  'conf': 0.47928768396377563,\n",
       "  'pred_class': 6,\n",
       "  'true_class': 28,\n",
       "  'image_id': 217},\n",
       " {'bbox': {'x1': tensor(239, device='cuda:0', dtype=torch.int32),\n",
       "   'y1': tensor(85, device='cuda:0', dtype=torch.int32),\n",
       "   'x2': tensor(279, device='cuda:0', dtype=torch.int32),\n",
       "   'y2': tensor(102, device='cuda:0', dtype=torch.int32)},\n",
       "  'conf': 0.40448257327079773,\n",
       "  'pred_class': 3,\n",
       "  'true_class': 28,\n",
       "  'image_id': 217}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "predictions[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
