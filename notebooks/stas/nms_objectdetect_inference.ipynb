{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import glob\n",
    "from hydra import compose, initialize\n",
    "import hydra\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import yaml\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "from dl4cv.utils.utils import set_seed\n",
    "from dl4cv.lightning_classes.plmodel import LitODModel\n",
    "from dl4cv.datasets import build_taco \n",
    "from dl4cv.datasets.taco_data import taco_val_test_collate_fn\n",
    "from dl4cv.utils.object_detect_utils import get_iou, fix_orientation, mAP_calc, calc_total_mAP\n",
    "from tqdm import tqdm\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hydra.core.global_hydra.GlobalHydra.instance().clear()\n",
    "initialize(config_path=\"./configs\")\n",
    "inference_cfg = compose(config_name=\"config_taco_training\")\n",
    "inference_cfg[\"inference\"][\"run_name\"] = 'Resnet50_Whale_bs1'\n",
    "inference_cfg[\"inference\"][\"device\"] = 'cuda:1'\n",
    "path = f\"outputs/{inference_cfg.inference.run_name}/.hydra/config.yaml\"\n",
    "with open(path) as cfg:\n",
    "    cfg_yaml = yaml.safe_load(cfg)\n",
    "cfg_yaml[\"inference\"] = inference_cfg[\"inference\"]\n",
    "cfg_yaml[\"datamodule\"][\"test\"][\"params\"][\"num_to_return\"] = 100\n",
    "cfg = OmegaConf.create(cfg_yaml)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(cfg: DictConfig) -> None:\n",
    "    \"\"\"\n",
    "    Run pytorch-lightning model inference\n",
    "    Args:\n",
    "        cfg: hydra config\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    set_seed(cfg.training.seed)\n",
    "\n",
    "    device = torch.device(cfg.inference.device)\n",
    "\n",
    "    model_names = glob.glob(f\"outputs/{cfg.inference.run_name}/saved_models/*.ckpt\")\n",
    "    _, _, test_set,_ = build_taco(cfg)\n",
    "    test_set.num_to_return = 100\n",
    "    # Dirty trick to get the ground truth boxes\n",
    "    loader = torch.utils.data.DataLoader(\n",
    "        test_set,\n",
    "        collate_fn=taco_val_test_collate_fn,\n",
    "        batch_size=1,\n",
    "        num_workers=1,\n",
    "        shuffle=False,\n",
    "    )\n",
    "    lit_model = LitODModel.load_from_checkpoint(checkpoint_path=model_names[0], cfg=cfg)\n",
    "    lit_model.to(device)\n",
    "    predictions = []\n",
    "    for batch in tqdm(loader):\n",
    "        # move batch elements to device\n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        predictions.append(\n",
    "            lit_model.nms_on_image(\n",
    "                batch,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return predictions\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = main(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find an index in predictions where the kept_preds are not empty\n",
    "valids = []\n",
    "for i in range(len(predictions)):\n",
    "    if len(predictions[i]['kept_preds']) > 0:\n",
    "        valids.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = []\n",
    "truth = []\n",
    "\n",
    "for i in range(len(predictions)):\n",
    "    if len(predictions[i]['kept_preds']) > 0:\n",
    "        pred.append(predictions[i]['kept_preds'])\n",
    "        _gt_boxes = predictions[i]['gt_regions']\n",
    "        _gt_classes = predictions[i]['gt_labels']\n",
    "        _truth = []\n",
    "        for j in range(len(_gt_boxes)):\n",
    "            _box = {'x1':_gt_boxes[j][0].item(), 'x2':_gt_boxes[j][1].item(), 'y1':_gt_boxes[j][2].item(), 'y2':_gt_boxes[j][3].item()}\n",
    "            _class = _gt_classes[j].item()\n",
    "            _truth.append({'bbox':_box, 'pred_class':_class})\n",
    "        truth.append(_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_total_mAP(pred,truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mAP_calc(pred,truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_total_mAP(pred,truth) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mAP_calc(pred,truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
