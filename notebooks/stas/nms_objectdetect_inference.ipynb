{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import glob\n",
    "from hydra import compose, initialize\n",
    "import hydra\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import yaml\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "from dl4cv.utils.utils import set_seed\n",
    "from dl4cv.lightning_classes.plmodel import LitODModel\n",
    "from dl4cv.datasets import build_taco \n",
    "from dl4cv.datasets.taco_data import taco_val_test_collate_fn\n",
    "from dl4cv.utils.object_detect_utils import get_iou, fix_orientation\n",
    "from tqdm import tqdm\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hydra.core.global_hydra.GlobalHydra.instance().clear()\n",
    "initialize(config_path=\"./configs\")\n",
    "inference_cfg = compose(config_name=\"config_taco_training\")\n",
    "inference_cfg[\"inference\"][\"run_name\"] = 'Resnet50_Whale_bs1'\n",
    "inference_cfg[\"inference\"][\"device\"] = 'cuda:1'\n",
    "path = f\"outputs/{inference_cfg.inference.run_name}/.hydra/config.yaml\"\n",
    "with open(path) as cfg:\n",
    "    cfg_yaml = yaml.safe_load(cfg)\n",
    "cfg_yaml[\"inference\"] = inference_cfg[\"inference\"]\n",
    "cfg_yaml[\"datamodule\"][\"test\"][\"params\"][\"num_to_return\"] = 100\n",
    "cfg = OmegaConf.create(cfg_yaml)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(cfg: DictConfig) -> None:\n",
    "    \"\"\"\n",
    "    Run pytorch-lightning model inference\n",
    "    Args:\n",
    "        cfg: hydra config\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    set_seed(cfg.training.seed)\n",
    "\n",
    "    device = torch.device(cfg.inference.device)\n",
    "\n",
    "    model_names = glob.glob(f\"outputs/{cfg.inference.run_name}/saved_models/*.ckpt\")\n",
    "    _, _, test_set,_ = build_taco(cfg)\n",
    "    test_set.num_to_return = 100\n",
    "    # Dirty trick to get the ground truth boxes\n",
    "    loader = torch.utils.data.DataLoader(\n",
    "        test_set,\n",
    "        collate_fn=taco_val_test_collate_fn,\n",
    "        batch_size=1,\n",
    "        num_workers=1,\n",
    "        shuffle=False,\n",
    "    )\n",
    "    lit_model = LitODModel.load_from_checkpoint(checkpoint_path=model_names[0], cfg=cfg)\n",
    "    lit_model.to(device)\n",
    "    predictions = []\n",
    "    for batch in tqdm(loader):\n",
    "        # move batch elements to device\n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        predictions.append(\n",
    "            lit_model.nms_on_image(\n",
    "                batch,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return predictions\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [02:52<00:00,  1.45it/s]\n"
     ]
    }
   ],
   "source": [
    "predictions = main(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['kept_preds', 'P', 'gt_regions', 'gt_labels'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find an index in predictions where the kept_preds are not empty\n",
    "valids = []\n",
    "for i in range(len(predictions)):\n",
    "    if len(predictions[i]['kept_preds']) > 0:\n",
    "        valids.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kept_preds': [{'bbox': {'x1': 188, 'y1': 97, 'x2': 536, 'y2': 367},\n",
       "   'conf': 0.9986655712127686,\n",
       "   'pred_class': 9,\n",
       "   'true_class': 9,\n",
       "   'image_id': 217},\n",
       "  {'bbox': {'x1': 723, 'y1': 153, 'x2': 958, 'y2': 695},\n",
       "   'conf': 0.9917469024658203,\n",
       "   'pred_class': 19,\n",
       "   'true_class': 19,\n",
       "   'image_id': 217}],\n",
       " 'P': [{'bbox': {'x1': 723, 'y1': 158, 'x2': 958, 'y2': 695},\n",
       "   'conf': 0.974744439125061,\n",
       "   'pred_class': 19,\n",
       "   'true_class': 19,\n",
       "   'image_id': 217},\n",
       "  {'bbox': {'x1': 188, 'y1': 99, 'x2': 548, 'y2': 395},\n",
       "   'conf': 0.9873728156089783,\n",
       "   'pred_class': 9,\n",
       "   'true_class': 9,\n",
       "   'image_id': 217},\n",
       "  {'bbox': {'x1': 188, 'y1': 88, 'x2': 549, 'y2': 397},\n",
       "   'conf': 0.7924853563308716,\n",
       "   'pred_class': 9,\n",
       "   'true_class': 9,\n",
       "   'image_id': 217},\n",
       "  {'bbox': {'x1': 189, 'y1': 99, 'x2': 521, 'y2': 368},\n",
       "   'conf': 0.9373885989189148,\n",
       "   'pred_class': 9,\n",
       "   'true_class': 9,\n",
       "   'image_id': 217},\n",
       "  {'bbox': {'x1': 187, 'y1': 101, 'x2': 536, 'y2': 396},\n",
       "   'conf': 0.939198911190033,\n",
       "   'pred_class': 9,\n",
       "   'true_class': 9,\n",
       "   'image_id': 217},\n",
       "  {'bbox': {'x1': 187, 'y1': 89, 'x2': 552, 'y2': 397},\n",
       "   'conf': 0.9664170145988464,\n",
       "   'pred_class': 9,\n",
       "   'true_class': 9,\n",
       "   'image_id': 217},\n",
       "  {'bbox': {'x1': 187, 'y1': 85, 'x2': 593, 'y2': 396},\n",
       "   'conf': 0.9439691305160522,\n",
       "   'pred_class': 9,\n",
       "   'true_class': 9,\n",
       "   'image_id': 217},\n",
       "  {'bbox': {'x1': 723, 'y1': 153, 'x2': 958, 'y2': 695},\n",
       "   'conf': 0.9917469024658203,\n",
       "   'pred_class': 19,\n",
       "   'true_class': 19,\n",
       "   'image_id': 217},\n",
       "  {'bbox': {'x1': 189, 'y1': 99, 'x2': 615, 'y2': 397},\n",
       "   'conf': 0.9131669402122498,\n",
       "   'pred_class': 9,\n",
       "   'true_class': 9,\n",
       "   'image_id': 217},\n",
       "  {'bbox': {'x1': 188, 'y1': 99, 'x2': 548, 'y2': 424},\n",
       "   'conf': 0.9571791291236877,\n",
       "   'pred_class': 9,\n",
       "   'true_class': 9,\n",
       "   'image_id': 217},\n",
       "  {'bbox': {'x1': 188, 'y1': 97, 'x2': 536, 'y2': 367},\n",
       "   'conf': 0.9986655712127686,\n",
       "   'pred_class': 9,\n",
       "   'true_class': 9,\n",
       "   'image_id': 217},\n",
       "  {'bbox': {'x1': 189, 'y1': 88, 'x2': 615, 'y2': 397},\n",
       "   'conf': 0.9661418795585632,\n",
       "   'pred_class': 9,\n",
       "   'true_class': 9,\n",
       "   'image_id': 217},\n",
       "  {'bbox': {'x1': 187, 'y1': 85, 'x2': 552, 'y2': 397},\n",
       "   'conf': 0.9786087870597839,\n",
       "   'pred_class': 9,\n",
       "   'true_class': 9,\n",
       "   'image_id': 217},\n",
       "  {'bbox': {'x1': 188, 'y1': 97, 'x2': 536, 'y2': 387},\n",
       "   'conf': 0.9973854422569275,\n",
       "   'pred_class': 9,\n",
       "   'true_class': 9,\n",
       "   'image_id': 217},\n",
       "  {'bbox': {'x1': 188, 'y1': 88, 'x2': 548, 'y2': 396},\n",
       "   'conf': 0.9864062666893005,\n",
       "   'pred_class': 9,\n",
       "   'true_class': 9,\n",
       "   'image_id': 217},\n",
       "  {'bbox': {'x1': 187, 'y1': 88, 'x2': 536, 'y2': 396},\n",
       "   'conf': 0.9790297746658325,\n",
       "   'pred_class': 9,\n",
       "   'true_class': 9,\n",
       "   'image_id': 217},\n",
       "  {'bbox': {'x1': 187, 'y1': 72, 'x2': 552, 'y2': 397},\n",
       "   'conf': 0.9868060350418091,\n",
       "   'pred_class': 9,\n",
       "   'true_class': 9,\n",
       "   'image_id': 217},\n",
       "  {'bbox': {'x1': 188, 'y1': 97, 'x2': 549, 'y2': 397},\n",
       "   'conf': 0.9127528667449951,\n",
       "   'pred_class': 9,\n",
       "   'true_class': 9,\n",
       "   'image_id': 217},\n",
       "  {'bbox': {'x1': 188, 'y1': 99, 'x2': 548, 'y2': 396},\n",
       "   'conf': 0.991853654384613,\n",
       "   'pred_class': 9,\n",
       "   'true_class': 9,\n",
       "   'image_id': 217},\n",
       "  {'bbox': {'x1': 188, 'y1': 97, 'x2': 549, 'y2': 425},\n",
       "   'conf': 0.9818690419197083,\n",
       "   'pred_class': 9,\n",
       "   'true_class': 9,\n",
       "   'image_id': 217},\n",
       "  {'bbox': {'x1': 723, 'y1': 153, 'x2': 960, 'y2': 695},\n",
       "   'conf': 0.9858319759368896,\n",
       "   'pred_class': 19,\n",
       "   'true_class': 19,\n",
       "   'image_id': 217},\n",
       "  {'bbox': {'x1': 189, 'y1': 88, 'x2': 548, 'y2': 396},\n",
       "   'conf': 0.973292350769043,\n",
       "   'pred_class': 9,\n",
       "   'true_class': 9,\n",
       "   'image_id': 217},\n",
       "  {'bbox': {'x1': 189, 'y1': 88, 'x2': 521, 'y2': 387},\n",
       "   'conf': 0.9379550814628601,\n",
       "   'pred_class': 9,\n",
       "   'true_class': 9,\n",
       "   'image_id': 217},\n",
       "  {'bbox': {'x1': 187, 'y1': 85, 'x2': 536, 'y2': 396},\n",
       "   'conf': 0.9709298014640808,\n",
       "   'pred_class': 9,\n",
       "   'true_class': 9,\n",
       "   'image_id': 217},\n",
       "  {'bbox': {'x1': 189, 'y1': 88, 'x2': 548, 'y2': 397},\n",
       "   'conf': 0.9633142352104187,\n",
       "   'pred_class': 9,\n",
       "   'true_class': 9,\n",
       "   'image_id': 217},\n",
       "  {'bbox': {'x1': 188, 'y1': 88, 'x2': 549, 'y2': 425},\n",
       "   'conf': 0.9948064684867859,\n",
       "   'pred_class': 9,\n",
       "   'true_class': 9,\n",
       "   'image_id': 217},\n",
       "  {'bbox': {'x1': 87, 'y1': 88, 'x2': 549, 'y2': 425},\n",
       "   'conf': 0.8045661449432373,\n",
       "   'pred_class': 9,\n",
       "   'true_class': 9,\n",
       "   'image_id': 217},\n",
       "  {'bbox': {'x1': 536, 'y1': 116, 'x2': 666, 'y2': 222},\n",
       "   'conf': 0.9711243510246277,\n",
       "   'pred_class': 28,\n",
       "   'true_class': 28,\n",
       "   'image_id': 217},\n",
       "  {'bbox': {'x1': 71, 'y1': 198, 'x2': 160, 'y2': 303},\n",
       "   'conf': 0.9960021376609802,\n",
       "   'pred_class': 28,\n",
       "   'true_class': 28,\n",
       "   'image_id': 217},\n",
       "  {'bbox': {'x1': 145, 'y1': 477, 'x2': 202, 'y2': 566},\n",
       "   'conf': 1.0,\n",
       "   'pred_class': 28,\n",
       "   'true_class': 28,\n",
       "   'image_id': 217},\n",
       "  {'bbox': {'x1': 932, 'y1': 165, 'x2': 1033, 'y2': 620},\n",
       "   'conf': 0.9876341819763184,\n",
       "   'pred_class': 28,\n",
       "   'true_class': 28,\n",
       "   'image_id': 217},\n",
       "  {'bbox': {'x1': 1117, 'y1': 255, 'x2': 1128, 'y2': 275},\n",
       "   'conf': 0.993520200252533,\n",
       "   'pred_class': 28,\n",
       "   'true_class': 28,\n",
       "   'image_id': 217},\n",
       "  {'bbox': {'x1': 34, 'y1': 265, 'x2': 103, 'y2': 309},\n",
       "   'conf': 0.9999809265136719,\n",
       "   'pred_class': 28,\n",
       "   'true_class': 28,\n",
       "   'image_id': 217},\n",
       "  {'bbox': {'x1': 982, 'y1': 686, 'x2': 996, 'y2': 709},\n",
       "   'conf': 0.9991543292999268,\n",
       "   'pred_class': 28,\n",
       "   'true_class': 28,\n",
       "   'image_id': 217},\n",
       "  {'bbox': {'x1': 666, 'y1': 619, 'x2': 701, 'y2': 642},\n",
       "   'conf': 0.9993973970413208,\n",
       "   'pred_class': 28,\n",
       "   'true_class': 28,\n",
       "   'image_id': 217},\n",
       "  {'bbox': {'x1': 1196, 'y1': 631, 'x2': 1206, 'y2': 684},\n",
       "   'conf': 0.9999940395355225,\n",
       "   'pred_class': 28,\n",
       "   'true_class': 28,\n",
       "   'image_id': 217},\n",
       "  {'bbox': {'x1': 533, 'y1': 381, 'x2': 557, 'y2': 582},\n",
       "   'conf': 0.9984650611877441,\n",
       "   'pred_class': 28,\n",
       "   'true_class': 28,\n",
       "   'image_id': 217},\n",
       "  {'bbox': {'x1': 239, 'y1': 123, 'x2': 259, 'y2': 133},\n",
       "   'conf': 0.9922860860824585,\n",
       "   'pred_class': 28,\n",
       "   'true_class': 28,\n",
       "   'image_id': 217},\n",
       "  {'bbox': {'x1': 920, 'y1': 341, 'x2': 972, 'y2': 518},\n",
       "   'conf': 0.9999822378158569,\n",
       "   'pred_class': 28,\n",
       "   'true_class': 28,\n",
       "   'image_id': 217},\n",
       "  {'bbox': {'x1': 27, 'y1': 240, 'x2': 72, 'y2': 248},\n",
       "   'conf': 0.9999325275421143,\n",
       "   'pred_class': 28,\n",
       "   'true_class': 28,\n",
       "   'image_id': 217},\n",
       "  {'bbox': {'x1': 894, 'y1': 408, 'x2': 914, 'y2': 460},\n",
       "   'conf': 0.9998301267623901,\n",
       "   'pred_class': 28,\n",
       "   'true_class': 28,\n",
       "   'image_id': 217},\n",
       "  {'bbox': {'x1': 216, 'y1': 586, 'x2': 239, 'y2': 610},\n",
       "   'conf': 0.999996542930603,\n",
       "   'pred_class': 28,\n",
       "   'true_class': 28,\n",
       "   'image_id': 217},\n",
       "  {'bbox': {'x1': 948, 'y1': 157, 'x2': 988, 'y2': 242},\n",
       "   'conf': 0.9994375109672546,\n",
       "   'pred_class': 28,\n",
       "   'true_class': 28,\n",
       "   'image_id': 217},\n",
       "  {'bbox': {'x1': 1025, 'y1': 76, 'x2': 1051, 'y2': 161},\n",
       "   'conf': 0.9997121691703796,\n",
       "   'pred_class': 28,\n",
       "   'true_class': 28,\n",
       "   'image_id': 217},\n",
       "  {'bbox': {'x1': 505, 'y1': 160, 'x2': 540, 'y2': 228},\n",
       "   'conf': 0.9999167919158936,\n",
       "   'pred_class': 28,\n",
       "   'true_class': 28,\n",
       "   'image_id': 217},\n",
       "  {'bbox': {'x1': 1074, 'y1': 524, 'x2': 1087, 'y2': 601},\n",
       "   'conf': 0.9999991655349731,\n",
       "   'pred_class': 28,\n",
       "   'true_class': 28,\n",
       "   'image_id': 217},\n",
       "  {'bbox': {'x1': 896, 'y1': 139, 'x2': 985, 'y2': 434},\n",
       "   'conf': 0.9695731401443481,\n",
       "   'pred_class': 28,\n",
       "   'true_class': 28,\n",
       "   'image_id': 217},\n",
       "  {'bbox': {'x1': 889, 'y1': 581, 'x2': 916, 'y2': 650},\n",
       "   'conf': 0.9999691247940063,\n",
       "   'pred_class': 28,\n",
       "   'true_class': 28,\n",
       "   'image_id': 217},\n",
       "  {'bbox': {'x1': 896, 'y1': 240, 'x2': 985, 'y2': 434},\n",
       "   'conf': 0.9973239898681641,\n",
       "   'pred_class': 28,\n",
       "   'true_class': 28,\n",
       "   'image_id': 217},\n",
       "  {'bbox': {'x1': 388, 'y1': 316, 'x2': 415, 'y2': 347},\n",
       "   'conf': 0.9999464750289917,\n",
       "   'pred_class': 28,\n",
       "   'true_class': 28,\n",
       "   'image_id': 217},\n",
       "  {'bbox': {'x1': 135, 'y1': 477, 'x2': 206, 'y2': 576},\n",
       "   'conf': 0.9999997615814209,\n",
       "   'pred_class': 28,\n",
       "   'true_class': 28,\n",
       "   'image_id': 217},\n",
       "  {'bbox': {'x1': 1204, 'y1': 203, 'x2': 1275, 'y2': 632},\n",
       "   'conf': 0.9998353719711304,\n",
       "   'pred_class': 28,\n",
       "   'true_class': 28,\n",
       "   'image_id': 217},\n",
       "  {'bbox': {'x1': 1096, 'y1': 587, 'x2': 1115, 'y2': 656},\n",
       "   'conf': 0.9999998807907104,\n",
       "   'pred_class': 28,\n",
       "   'true_class': 28,\n",
       "   'image_id': 217},\n",
       "  {'bbox': {'x1': 759, 'y1': 615, 'x2': 771, 'y2': 643},\n",
       "   'conf': 0.9981895089149475,\n",
       "   'pred_class': 28,\n",
       "   'true_class': 28,\n",
       "   'image_id': 217},\n",
       "  {'bbox': {'x1': 862, 'y1': 460, 'x2': 896, 'y2': 505},\n",
       "   'conf': 0.9981676340103149,\n",
       "   'pred_class': 28,\n",
       "   'true_class': 28,\n",
       "   'image_id': 217},\n",
       "  {'bbox': {'x1': 102, 'y1': 672, 'x2': 122, 'y2': 691},\n",
       "   'conf': 0.9999972581863403,\n",
       "   'pred_class': 28,\n",
       "   'true_class': 28,\n",
       "   'image_id': 217},\n",
       "  {'bbox': {'x1': 940, 'y1': 119, 'x2': 998, 'y2': 242},\n",
       "   'conf': 0.9991195797920227,\n",
       "   'pred_class': 28,\n",
       "   'true_class': 28,\n",
       "   'image_id': 217},\n",
       "  {'bbox': {'x1': 82, 'y1': 156, 'x2': 102, 'y2': 200},\n",
       "   'conf': 0.9963321089744568,\n",
       "   'pred_class': 28,\n",
       "   'true_class': 28,\n",
       "   'image_id': 217},\n",
       "  {'bbox': {'x1': 931, 'y1': 340, 'x2': 943, 'y2': 366},\n",
       "   'conf': 0.9998388290405273,\n",
       "   'pred_class': 28,\n",
       "   'true_class': 28,\n",
       "   'image_id': 217},\n",
       "  {'bbox': {'x1': 157, 'y1': 538, 'x2': 178, 'y2': 566},\n",
       "   'conf': 0.9999971389770508,\n",
       "   'pred_class': 28,\n",
       "   'true_class': 28,\n",
       "   'image_id': 217},\n",
       "  {'bbox': {'x1': 942, 'y1': 139, 'x2': 983, 'y2': 259},\n",
       "   'conf': 0.9972805976867676,\n",
       "   'pred_class': 28,\n",
       "   'true_class': 28,\n",
       "   'image_id': 217},\n",
       "  {'bbox': {'x1': 207, 'y1': 192, 'x2': 244, 'y2': 311},\n",
       "   'conf': 0.9999088048934937,\n",
       "   'pred_class': 28,\n",
       "   'true_class': 28,\n",
       "   'image_id': 217},\n",
       "  {'bbox': {'x1': 1221, 'y1': 268, 'x2': 1234, 'y2': 315},\n",
       "   'conf': 0.9999998807907104,\n",
       "   'pred_class': 28,\n",
       "   'true_class': 28,\n",
       "   'image_id': 217},\n",
       "  {'bbox': {'x1': 507, 'y1': 118, 'x2': 549, 'y2': 152},\n",
       "   'conf': 0.47419804334640503,\n",
       "   'pred_class': 28,\n",
       "   'true_class': 28,\n",
       "   'image_id': 217},\n",
       "  {'bbox': {'x1': 285, 'y1': 330, 'x2': 306, 'y2': 347},\n",
       "   'conf': 0.9003179669380188,\n",
       "   'pred_class': 28,\n",
       "   'true_class': 28,\n",
       "   'image_id': 217},\n",
       "  {'bbox': {'x1': 38, 'y1': 540, 'x2': 56, 'y2': 558},\n",
       "   'conf': 0.9999407529830933,\n",
       "   'pred_class': 28,\n",
       "   'true_class': 28,\n",
       "   'image_id': 217},\n",
       "  {'bbox': {'x1': 713, 'y1': 645, 'x2': 725, 'y2': 662},\n",
       "   'conf': 0.998364269733429,\n",
       "   'pred_class': 28,\n",
       "   'true_class': 28,\n",
       "   'image_id': 217},\n",
       "  {'bbox': {'x1': 1161, 'y1': 241, 'x2': 1176, 'y2': 289},\n",
       "   'conf': 0.9997634291648865,\n",
       "   'pred_class': 28,\n",
       "   'true_class': 28,\n",
       "   'image_id': 217},\n",
       "  {'bbox': {'x1': 1078, 'y1': 524, 'x2': 1087, 'y2': 576},\n",
       "   'conf': 0.9999986886978149,\n",
       "   'pred_class': 28,\n",
       "   'true_class': 28,\n",
       "   'image_id': 217},\n",
       "  {'bbox': {'x1': 449, 'y1': 146, 'x2': 512, 'y2': 177},\n",
       "   'conf': 0.8707200884819031,\n",
       "   'pred_class': 28,\n",
       "   'true_class': 28,\n",
       "   'image_id': 217},\n",
       "  {'bbox': {'x1': 842, 'y1': 173, 'x2': 849, 'y2': 250},\n",
       "   'conf': 0.9999802112579346,\n",
       "   'pred_class': 28,\n",
       "   'true_class': 28,\n",
       "   'image_id': 217},\n",
       "  {'bbox': {'x1': 375, 'y1': 601, 'x2': 424, 'y2': 634},\n",
       "   'conf': 0.9999871253967285,\n",
       "   'pred_class': 28,\n",
       "   'true_class': 28,\n",
       "   'image_id': 217},\n",
       "  {'bbox': {'x1': 183, 'y1': 675, 'x2': 209, 'y2': 695},\n",
       "   'conf': 0.9999582767486572,\n",
       "   'pred_class': 28,\n",
       "   'true_class': 28,\n",
       "   'image_id': 217},\n",
       "  {'bbox': {'x1': 891, 'y1': 362, 'x2': 937, 'y2': 519},\n",
       "   'conf': 0.9984329342842102,\n",
       "   'pred_class': 28,\n",
       "   'true_class': 28,\n",
       "   'image_id': 217},\n",
       "  {'bbox': {'x1': 197, 'y1': 149, 'x2': 244, 'y2': 311},\n",
       "   'conf': 0.984312891960144,\n",
       "   'pred_class': 28,\n",
       "   'true_class': 28,\n",
       "   'image_id': 217},\n",
       "  {'bbox': {'x1': 120, 'y1': 198, 'x2': 161, 'y2': 242},\n",
       "   'conf': 0.9999963045120239,\n",
       "   'pred_class': 28,\n",
       "   'true_class': 28,\n",
       "   'image_id': 217},\n",
       "  {'bbox': {'x1': 539, 'y1': 411, 'x2': 558, 'y2': 583},\n",
       "   'conf': 0.9975348711013794,\n",
       "   'pred_class': 28,\n",
       "   'true_class': 28,\n",
       "   'image_id': 217},\n",
       "  {'bbox': {'x1': 971, 'y1': 240, 'x2': 987, 'y2': 354},\n",
       "   'conf': 0.9873663187026978,\n",
       "   'pred_class': 28,\n",
       "   'true_class': 28,\n",
       "   'image_id': 217},\n",
       "  {'bbox': {'x1': 159, 'y1': 656, 'x2': 191, 'y2': 695},\n",
       "   'conf': 0.9999997615814209,\n",
       "   'pred_class': 28,\n",
       "   'true_class': 28,\n",
       "   'image_id': 217},\n",
       "  {'bbox': {'x1': 543, 'y1': 467, 'x2': 552, 'y2': 571},\n",
       "   'conf': 0.999754011631012,\n",
       "   'pred_class': 28,\n",
       "   'true_class': 28,\n",
       "   'image_id': 217},\n",
       "  {'bbox': {'x1': 896, 'y1': 139, 'x2': 989, 'y2': 434},\n",
       "   'conf': 0.8905661702156067,\n",
       "   'pred_class': 28,\n",
       "   'true_class': 28,\n",
       "   'image_id': 217},\n",
       "  {'bbox': {'x1': 1250, 'y1': 360, 'x2': 1264, 'y2': 392},\n",
       "   'conf': 0.9998918771743774,\n",
       "   'pred_class': 28,\n",
       "   'true_class': 28,\n",
       "   'image_id': 217},\n",
       "  {'bbox': {'x1': 1065, 'y1': 524, 'x2': 1087, 'y2': 638},\n",
       "   'conf': 0.9997441172599792,\n",
       "   'pred_class': 28,\n",
       "   'true_class': 28,\n",
       "   'image_id': 217},\n",
       "  {'bbox': {'x1': 461, 'y1': 303, 'x2': 498, 'y2': 335},\n",
       "   'conf': 0.999982476234436,\n",
       "   'pred_class': 28,\n",
       "   'true_class': 28,\n",
       "   'image_id': 217},\n",
       "  {'bbox': {'x1': 584, 'y1': 216, 'x2': 635, 'y2': 281},\n",
       "   'conf': 0.9999997615814209,\n",
       "   'pred_class': 28,\n",
       "   'true_class': 28,\n",
       "   'image_id': 217},\n",
       "  {'bbox': {'x1': 863, 'y1': 470, 'x2': 878, 'y2': 501},\n",
       "   'conf': 0.9999727010726929,\n",
       "   'pred_class': 28,\n",
       "   'true_class': 28,\n",
       "   'image_id': 217},\n",
       "  {'bbox': {'x1': 484, 'y1': 600, 'x2': 502, 'y2': 614},\n",
       "   'conf': 0.9817075729370117,\n",
       "   'pred_class': 28,\n",
       "   'true_class': 28,\n",
       "   'image_id': 217},\n",
       "  {'bbox': {'x1': 839, 'y1': 400, 'x2': 854, 'y2': 439},\n",
       "   'conf': 0.9787944555282593,\n",
       "   'pred_class': 28,\n",
       "   'true_class': 28,\n",
       "   'image_id': 217},\n",
       "  {'bbox': {'x1': 764, 'y1': 661, 'x2': 782, 'y2': 703},\n",
       "   'conf': 0.9999784231185913,\n",
       "   'pred_class': 28,\n",
       "   'true_class': 28,\n",
       "   'image_id': 217},\n",
       "  {'bbox': {'x1': 905, 'y1': 364, 'x2': 937, 'y2': 524},\n",
       "   'conf': 0.9998942613601685,\n",
       "   'pred_class': 28,\n",
       "   'true_class': 28,\n",
       "   'image_id': 217},\n",
       "  {'bbox': {'x1': 543, 'y1': 424, 'x2': 557, 'y2': 571},\n",
       "   'conf': 0.9927135109901428,\n",
       "   'pred_class': 28,\n",
       "   'true_class': 28,\n",
       "   'image_id': 217},\n",
       "  {'bbox': {'x1': 974, 'y1': 39, 'x2': 1056, 'y2': 368},\n",
       "   'conf': 0.9728276133537292,\n",
       "   'pred_class': 28,\n",
       "   'true_class': 28,\n",
       "   'image_id': 217},\n",
       "  {'bbox': {'x1': 405, 'y1': 386, 'x2': 428, 'y2': 402},\n",
       "   'conf': 0.9999852180480957,\n",
       "   'pred_class': 28,\n",
       "   'true_class': 28,\n",
       "   'image_id': 217},\n",
       "  {'bbox': {'x1': 766, 'y1': 222, 'x2': 825, 'y2': 348},\n",
       "   'conf': 0.999981164932251,\n",
       "   'pred_class': 28,\n",
       "   'true_class': 28,\n",
       "   'image_id': 217},\n",
       "  {'bbox': {'x1': 464, 'y1': 49, 'x2': 477, 'y2': 71},\n",
       "   'conf': 0.9999971389770508,\n",
       "   'pred_class': 28,\n",
       "   'true_class': 28,\n",
       "   'image_id': 217},\n",
       "  {'bbox': {'x1': 213, 'y1': 121, 'x2': 297, 'y2': 143},\n",
       "   'conf': 0.9995338916778564,\n",
       "   'pred_class': 28,\n",
       "   'true_class': 28,\n",
       "   'image_id': 217},\n",
       "  {'bbox': {'x1': 654, 'y1': 612, 'x2': 688, 'y2': 634},\n",
       "   'conf': 0.9962455630302429,\n",
       "   'pred_class': 28,\n",
       "   'true_class': 28,\n",
       "   'image_id': 217},\n",
       "  {'bbox': {'x1': 116, 'y1': 361, 'x2': 462, 'y2': 573},\n",
       "   'conf': 0.9431079030036926,\n",
       "   'pred_class': 28,\n",
       "   'true_class': 28,\n",
       "   'image_id': 217},\n",
       "  {'bbox': {'x1': 493, 'y1': 34, 'x2': 542, 'y2': 65},\n",
       "   'conf': 0.9999991655349731,\n",
       "   'pred_class': 28,\n",
       "   'true_class': 28,\n",
       "   'image_id': 217},\n",
       "  {'bbox': {'x1': 246, 'y1': 196, 'x2': 267, 'y2': 235},\n",
       "   'conf': 0.9549481272697449,\n",
       "   'pred_class': 28,\n",
       "   'true_class': 28,\n",
       "   'image_id': 217}],\n",
       " 'gt_regions': tensor([[184, 546,  87, 397],\n",
       "         [722, 982, 152, 719]], device='cuda:1'),\n",
       " 'gt_labels': tensor([ 9, 19], device='cuda:1')}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[3]\n",
    "predictions[4]\n",
    "predictions[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = []\n",
    "truth = []\n",
    "\n",
    "for i in range(len(predictions)):\n",
    "    if len(predictions[i]['kept_preds']) > 0:\n",
    "        pred.append(predictions[i]['kept_preds'])\n",
    "        _gt_boxes = predictions[i]['gt_regions']\n",
    "        _gt_classes = predictions[i]['gt_labels']\n",
    "        _truth = []\n",
    "        for j in range(len(_gt_boxes)):\n",
    "            _box = {'x1':_gt_boxes[j][0].item(), 'x2':_gt_boxes[j][1].item(), 'y1':_gt_boxes[j][2].item(), 'y2':_gt_boxes[j][3].item()}\n",
    "            _class = _gt_classes[j].item()\n",
    "            _truth.append({'bbox':_box, 'pred_class':_class})\n",
    "        truth.append(_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'bbox': {'x1': 805, 'y1': 541, 'x2': 859, 'y2': 548},\n",
       "  'conf': 0.8125687837600708,\n",
       "  'pred_class': 20,\n",
       "  'true_class': 28,\n",
       "  'image_id': 1338},\n",
       " {'bbox': {'x1': 421, 'y1': 166, 'x2': 608, 'y2': 316},\n",
       "  'conf': 0.7461764812469482,\n",
       "  'pred_class': 8,\n",
       "  'true_class': 8,\n",
       "  'image_id': 1338}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[198]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_by_class(preds,truths):\n",
    "    pred_by_class = {i:[] for i in range(29)}\n",
    "    truth_by_class = {i:[] for i in range(29)}\n",
    "    for pred in preds:\n",
    "        if pred['true_class'] == 28:\n",
    "            continue\n",
    "        pred_by_class[pred['pred_class']].append(pred)\n",
    "    \n",
    "    for truth in truths:\n",
    "        truth_by_class[truth['pred_class']].append(truth)\n",
    "\n",
    "    valids_preds = []\n",
    "    for i in range(len(pred_by_class)):\n",
    "        if len(pred_by_class[i]) > 0:\n",
    "            valids_preds.append(i)\n",
    "    \n",
    "    valids_truths = []\n",
    "    for i in range(len(truth_by_class)):\n",
    "        if len(truth_by_class[i]) > 0:\n",
    "            valids_truths.append(i)\n",
    "\n",
    "    preds_by_class = {i: pred_by_class[i] for i in valids_preds}\n",
    "    truth_by_class ={i: truth_by_class[i] for i in valids_truths}\n",
    "    \n",
    "    return preds_by_class,truth_by_class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'bbox': {'x1': 171, 'y1': 197, 'x2': 534, 'y2': 366}, 'conf': 0.9998736381530762, 'pred_class': 9, 'true_class': 9, 'image_id': 1105}, {'bbox': {'x1': 608, 'y1': 383, 'x2': 640, 'y2': 417}, 'conf': 0.995933473110199, 'pred_class': 27, 'true_class': 28, 'image_id': 1105}, {'bbox': {'x1': 592, 'y1': 381, 'x2': 888, 'y2': 497}, 'conf': 0.975390613079071, 'pred_class': 8, 'true_class': 8, 'image_id': 1105}]\n",
      "[{'bbox': {'x1': 607, 'x2': 885, 'y1': 381, 'y2': 492}, 'pred_class': 8}, {'bbox': {'x1': 178, 'x2': 533, 'y1': 199, 'y2': 357}, 'pred_class': 9}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({8: [{'bbox': {'x1': 592, 'y1': 381, 'x2': 888, 'y2': 497},\n",
       "    'conf': 0.975390613079071,\n",
       "    'pred_class': 8,\n",
       "    'true_class': 8,\n",
       "    'image_id': 1105}],\n",
       "  9: [{'bbox': {'x1': 171, 'y1': 197, 'x2': 534, 'y2': 366},\n",
       "    'conf': 0.9998736381530762,\n",
       "    'pred_class': 9,\n",
       "    'true_class': 9,\n",
       "    'image_id': 1105}]},\n",
       " {8: [{'bbox': {'x1': 607, 'x2': 885, 'y1': 381, 'y2': 492}, 'pred_class': 8}],\n",
       "  9: [{'bbox': {'x1': 178, 'x2': 533, 'y1': 199, 'y2': 357},\n",
       "    'pred_class': 9}]})"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(pred[4])\n",
    "print(truth[4])\n",
    "\n",
    "split_by_class(pred[4],truth[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc\n",
    "\n",
    "def calc_mAP_class(pred,truth):\n",
    "    # sort predictions by confidence\n",
    "    detections = sorted(pred, key=lambda k: k['conf'], reverse=True)\n",
    "\n",
    "    total_truth = len(truth) # TP + FN\n",
    "    \n",
    "    true_pos = 0\n",
    "    false_pos = 0\n",
    "\n",
    "    recalls = []\n",
    "    precisions = []\n",
    "\n",
    "    removed_truths = [False for t in truth]\n",
    "\n",
    "    # compute precision and recall for each detection\n",
    "    for d_idx, d in enumerate(detections):\n",
    "        ious = {}\n",
    "        for t_idx, t in enumerate(truth):\n",
    "            if removed_truths[t_idx]:\n",
    "                continue\n",
    "            \n",
    "            iou = get_iou(d['bbox'], t['bbox'])\n",
    "\n",
    "            if iou > 0.5:\n",
    "                ious[t_idx] = iou\n",
    "        \n",
    "        if len(ious) == 0:\n",
    "            false_pos += 1\n",
    "        elif len(ious) == 1:\n",
    "            true_pos += 1\n",
    "            removed_truths[list(ious.keys())[0]] = True\n",
    "        elif len(ious) > 1:\n",
    "            true_pos += 1\n",
    "            # find index with hishest iou\n",
    "            max_iou = 0\n",
    "            max_idx = 0\n",
    "            for idx, iou in ious.items():\n",
    "                if iou > max_iou:\n",
    "                    max_iou = iou\n",
    "                    max_idx = idx\n",
    "            removed_truths[max_idx] = True\n",
    "        else:\n",
    "            raise Exception('Something went wrong')\n",
    "        \n",
    "        precision = true_pos / (true_pos + false_pos)\n",
    "        recall = true_pos / total_truth\n",
    "\n",
    "        recalls.append(recall)\n",
    "        precisions.append(precision)\n",
    "\n",
    "    if len(precisions) == 1 and  precisions[0]==1.0:\n",
    "        return 1\n",
    "    elif len(precisions) == 1 and  precisions[0]==0.0:\n",
    "        return 0\n",
    "    else:\n",
    "        return auc(recalls, precisions)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mAPs_image(pred,truth):\n",
    "    preds_by_class, truths_by_class = split_by_class(pred,truth)\n",
    "    mAP = {}\n",
    "    for c in set(list(preds_by_class.keys()) + list(truths_by_class.keys())):\n",
    "        if c not in preds_by_class.keys() or c not in truths_by_class.keys():\n",
    "            mAP[c] = 0\n",
    "        else:\n",
    "            mAP[c] = calc_mAP_class(preds_by_class[c],truths_by_class[c])\n",
    "    return mAP\n",
    "\n",
    "def calc_total_mAP(pred, truth):\n",
    "    image_mAPs = {}\n",
    "    for i in range(len(pred)):\n",
    "        image_mAPs[i] = calc_mAPs_image(pred[i],truth[i])\n",
    "\n",
    "    print(f'Image mAPs: {image_mAPs}')\n",
    "    # mean to get class average\n",
    "    class_mAPs = {i:None for i in range(29)}\n",
    "    for i in range(29):\n",
    "        class_mAP = [image_mAPs[j][i] for j in range(len(image_mAPs)) if i in image_mAPs[j].keys()]\n",
    "        class_mAPs[i] = np.mean(class_mAP)\n",
    "    \n",
    "    # remove nan values\n",
    "    class_mAPs = {k:v for k,v in class_mAPs.items() if not(np.isnan(v))}\n",
    "    print(f'Class mAPs: {class_mAPs}')\n",
    "    return  np.mean(list(class_mAPs.values()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image mAPs: {0: {0: 0, 25: 0, 2: 0, 26: 0}, 1: {17: 0, 27: 1, 4: 0}, 2: {24: 0, 9: 1, 20: 1, 4: 0}, 3: {0: 0, 2: 1}, 4: {8: 1, 9: 1}, 5: {9: 1, 19: 1}, 6: {8: 1, 4: 0}, 7: {21: 1}, 8: {8: 1, 4: 0}, 9: {9: 0, 27: 0, 17: 1}, 10: {8: 0, 2: 0}, 11: {9: 0, 11: 0}, 12: {17: 1}, 13: {2: 0, 26: 0, 20: 0}, 14: {8: 1, 4: 1}, 15: {26: 0, 27: 0}, 16: {9: 1, 2: 0}, 17: {0: 0, 1: 0, 2: 0, 4: 0, 9: 0, 17: 0}, 18: {0: 0, 9: 1, 11: 1}, 19: {8: 1}, 20: {0: 0, 12: 0, 21: 1}, 21: {2: 1}, 22: {8: 0.3333333333333333, 9: 1, 4: 0.6000000000000001}, 23: {27: 0, 4: 0}, 24: {8: 1, 19: 0, 4: 1, 20: 1}, 25: {2: 0, 12: 0}, 26: {12: 1}, 27: {2: 0, 19: 0, 12: 0}, 28: {2: 0, 27: 0}, 29: {20: 0.5}, 30: {9: 1}, 31: {2: 1}, 32: {9: 1}, 33: {8: 0.5, 0: 0}, 34: {0: 0, 9: 0, 23: 1}, 35: {0: 0, 9: 0, 27: 0, 20: 0}, 36: {0: 0, 4: 1}, 37: {2: 1}, 38: {2: 0, 6: 0, 9: 0, 23: 1, 27: 1}, 39: {0: 0, 8: 0, 17: 0, 20: 0, 21: 0, 23: 0, 27: 0}, 40: {21: 0.5}, 41: {0: 0, 2: 0, 4: 0, 8: 0, 20: 1, 24: 0, 27: 0}, 42: {9: 0, 2: 0, 20: 0, 23: 0}, 43: {18: 0, 21: 0}, 44: {12: 1}, 45: {8: 0.5, 4: 1}, 46: {0: 0, 2: 0, 4: 0, 8: 1, 24: 0}, 47: {2: 1}, 48: {8: 1}, 49: {9: 0, 2: 1}, 50: {26: 1}, 51: {2: 0.5}, 52: {8: 0.5, 27: 0}, 53: {0: 0}, 54: {21: 1, 14: 0}, 55: {2: 0, 4: 0.25, 8: 0, 11: 0, 18: 0, 21: 0.5, 24: 0}, 56: {0: 1, 2: 0.2, 4: 0, 6: 1, 8: 0, 9: 0, 11: 0, 12: 0, 23: 0, 26: 0, 27: 0}, 57: {17: 0, 27: 1, 21: 0.5}, 58: {2: 1}, 59: {4: 1}, 60: {27: 1}, 61: {8: 0, 2: 0}, 62: {17: 0, 2: 0, 27: 0.0}, 63: {8: 1, 0: 0, 4: 0, 12: 0}, 64: {2: 0, 27: 0, 12: 0, 20: 0}, 65: {2: 0, 21: 0}, 66: {24: 1, 9: 0, 11: 0}, 67: {16: 0, 19: 0.5}, 68: {0: 0, 8: 0, 17: 1, 21: 0, 23: 0, 26: 0, 27: 0.0}, 69: {0: 0, 2: 0, 4: 0, 8: 0.0, 21: 0}, 70: {21: 1}, 71: {11: 1}, 72: {9: 1, 2: 1}, 73: {0: 0, 19: 1}, 74: {2: 1, 12: 0, 20: 0, 23: 0}, 75: {27: 0}, 76: {12: 1}, 77: {8: 1, 4: 0}, 78: {0: 0, 2: 0, 12: 0}, 79: {2: 0.25, 4: 1, 8: 0.25, 9: 0.2857142857142857, 18: 0, 23: 0}, 80: {19: 0, 12: 0}, 81: {2: 1}, 82: {9: 0.0, 19: 0}, 83: {2: 1, 11: 0}, 84: {9: 0.0, 2: 0}, 85: {0: 0, 9: 0}, 86: {27: 1}, 87: {21: 1}, 88: {0: 1, 8: 0, 2: 0}, 89: {26: 1, 27: 1}, 90: {18: 1}, 91: {0: 0, 8: 1, 9: 1, 11: 0, 20: 1}, 92: {8: 0, 2: 0}, 93: {2: 1, 26: 0}, 94: {0: 0, 8: 0, 2: 0}, 95: {4: 1}, 96: {8: 1}, 97: {2: 0, 26: 0, 19: 1, 12: 0}, 98: {2: 0}, 99: {2: 0}, 100: {0: 0, 2: 0.14285714285714285, 4: 0, 8: 0, 17: 1, 23: 0, 26: 0}, 101: {2: 1}, 102: {2: 1}, 103: {2: 1}, 104: {27: 1, 20: 0}, 105: {26: 1}, 106: {2: 0, 21: 0}, 107: {0: 0, 2: 1}, 108: {0: 0, 2: 0.0, 4: 0, 7: 0, 8: 0, 9: 0.0, 11: 0}, 109: {9: 1, 2: 1}, 110: {8: 1}, 111: {8: 1, 0: 0}, 112: {8: 0.0, 0: 0, 12: 0, 20: 0}, 113: {0: 0, 9: 0, 12: 0, 20: 0, 26: 0}, 114: {9: 1}, 115: {9: 0, 26: 0}, 116: {8: 1, 9: 0.5, 24: 0.5}, 117: {2: 0, 19: 0}, 118: {18: 0, 21: 1}, 119: {2: 0, 9: 0, 12: 0, 17: 1, 23: 0, 27: 1}, 120: {2: 1}, 121: {17: 0, 12: 0}, 122: {20: 0, 23: 1}, 123: {8: 1, 2: 1}, 124: {2: 0, 27: 0}, 125: {2: 0, 8: 1, 9: 0, 12: 0, 15: 0}, 126: {18: 0, 21: 1}, 127: {20: 0, 21: 1}, 128: {21: 1}, 129: {2: 0}, 130: {20: 1, 23: 1}, 131: {9: 1}, 132: {19: 1}, 133: {2: 1, 14: 0}, 134: {8: 0, 19: 0, 20: 0.14285714285714285}, 135: {2: 0.5}, 136: {0: 0, 1: 0, 2: 0, 9: 0, 19: 1}, 137: {2: 1}, 138: {9: 0, 2: 1, 20: 0.5}, 139: {9: 0, 21: 0}, 140: {0: 0, 2: 0}, 141: {19: 0, 12: 0}, 142: {17: 0, 4: 0}, 143: {11: 0, 26: 1, 2: 0, 20: 0}, 144: {2: 1, 23: 0}, 145: {17: 0, 27: 0, 21: 0}, 146: {8: 1, 4: 0}, 147: {19: 1}, 148: {11: 0, 2: 1, 19: 0, 23: 0}, 149: {9: 0, 19: 0.5}, 150: {8: 0.0, 4: 0}, 151: {21: 0}, 152: {8: 0, 2: 0, 20: 0}, 153: {18: 0, 21: 0}, 154: {11: 0, 20: 0.16666666666666666, 23: 0}, 155: {0: 0, 2: 0}, 156: {16: 0, 9: 0, 27: 0}, 157: {9: 1, 23: 0}, 158: {9: 0, 27: 0}, 159: {9: 0, 21: 0}, 160: {2: 0, 11: 0}, 161: {26: 0, 27: 0}, 162: {12: 1}, 163: {8: 0}, 164: {9: 0.6666666666666667}, 165: {9: 0, 2: 0}, 166: {2: 0.3333333333333333}, 167: {4: 1, 12: 0}, 168: {0: 0, 2: 0}, 169: {2: 0, 11: 0}, 170: {0: 0, 2: 0.16666666666666666, 4: 0, 8: 0, 9: 0, 27: 0}, 171: {8: 0, 12: 0, 20: 0}, 172: {2: 0}, 173: {2: 1}, 174: {12: 0, 23: 0}, 175: {24: 0, 2: 0}, 176: {4: 1}, 177: {8: 1}, 178: {0: 0, 2: 0}, 179: {27: 0, 21: 0}, 180: {19: 1}, 181: {19: 1}, 182: {0: 0, 2: 0, 4: 0.0, 8: 1, 18: 0, 21: 0.5, 27: 0}, 183: {2: 0, 5: 1, 11: 0, 18: 0, 21: 1, 24: 0, 27: 0}, 184: {9: 0, 2: 0, 4: 0, 20: 0}, 185: {27: 1}, 186: {4: 1}, 187: {8: 0, 4: 1}, 188: {0: 0, 9: 1}, 189: {8: 1, 20: 0}, 190: {2: 1}, 191: {4: 0.5, 12: 1}, 192: {19: 1, 4: 1}, 193: {16: 0, 12: 0}, 194: {4: 0, 11: 0, 20: 0, 24: 0, 27: 1}, 195: {9: 1, 20: 1}, 196: {26: 1}, 197: {2: 0, 12: 0}, 198: {8: 1, 4: 0}, 199: {8: 1}, 200: {16: 0, 2: 0}, 201: {2: 1}, 202: {0: 0, 8: 0, 2: 0.0, 4: 0}, 203: {0: 0, 2: 0, 4: 0, 8: 0, 9: 0, 12: 0, 21: 0, 27: 0}, 204: {2: 1}, 205: {12: 1}, 206: {16: 0, 12: 1}, 207: {8: 0}, 208: {0: 0, 20: 0.0, 21: 0}, 209: {9: 1, 2: 0}, 210: {8: 1, 24: 1}, 211: {2: 0, 19: 1}, 212: {21: 0.5}, 213: {0: 0, 2: 0, 20: 0}, 214: {8: 0, 2: 0}, 215: {18: 1, 21: 0.6666666666666667}, 216: {25: 0, 19: 0}, 217: {17: 0, 27: 1, 23: 0}, 218: {2: 1, 21: 0}, 219: {8: 0, 9: 0}, 220: {4: 0}, 221: {26: 0, 2: 0, 20: 0}, 222: {2: 1}, 223: {2: 0, 21: 0}, 224: {0: 0, 2: 1, 3: 0, 5: 0, 8: 1, 11: 0, 12: 0, 18: 0, 20: 0, 21: 0, 23: 0, 27: 0}, 225: {12: 0, 20: 0}, 226: {2: 1}, 227: {17: 0, 12: 0, 20: 0}, 228: {8: 0, 21: 0}, 229: {8: 1, 0: 0, 20: 0}, 230: {26: 1, 21: 0.5}, 231: {2: 1}, 232: {0: 0, 4: 0, 11: 0.0, 19: 0, 21: 0, 27: 0}, 233: {2: 1}, 234: {9: 0, 27: 1, 4: 0, 17: 0}, 235: {2: 0, 5: 0}}\n",
      "Class mAPs: {0: 0.045454545454545456, 1: 0.0, 2: 0.36092857142857143, 3: 0.0, 4: 0.31785714285714284, 5: 0.3333333333333333, 6: 0.5, 7: 0.0, 8: 0.48419540229885055, 9: 0.3618113912231559, 11: 0.1111111111111111, 12: 0.21875, 14: 0.0, 15: 0.0, 16: 0.0, 17: 0.3125, 18: 0.18181818181818182, 19: 0.5, 20: 0.2149859943977591, 21: 0.37962962962962965, 23: 0.21052631578947367, 24: 0.25, 25: 0.0, 26: 0.3333333333333333, 27: 0.32432432432432434}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.21762237107997648"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_total_mAP(pred,truth) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_average_precision(pred, truth, iou_threshold = 0.5, num_classes = 29, per_class = False):\n",
    "    # compute mAP https://github.com/aladdinpersson/Machine-Learning-Collection/blob/master/ML/Pytorch/object_detection/metrics/mean_avg_precision.py\n",
    "    # `pred` is given in [[{'bbox':{'x1', 'x2', 'y1', 'y2'}, 'class'(int), 'conf'}, ...], ...]\n",
    "    # `truth` is given in [[{'x1', 'x2', 'y1', 'y2', 'class'(int)}, more boxes...], ...]\n",
    "    average_precisions = []\n",
    "\n",
    "    # used for numerical stability later on\n",
    "    epsilon = 1e-6\n",
    "\n",
    "    for c in range(1, num_classes): # class '0' is background\n",
    "\n",
    "        TP = 0\n",
    "        FP = 0\n",
    "        total_true_bboxes = 0\n",
    "\n",
    "        # list detected(predicted) objects of class 'c'\n",
    "        detections = []\n",
    "\n",
    "        for idx, prs in enumerate(pred):\n",
    "          for pr in prs:\n",
    "            if pr['pred_class'] == c:\n",
    "                detections.append((pr['conf'], idx, pr['bbox']))\n",
    "\n",
    "        # make checkbox for checking whether gt object was detected\n",
    "        total_true_bboxes = 0\n",
    "        is_detected = []\n",
    "        for gts in pred:\n",
    "          is_detected.append([False for _ in gts])\n",
    "          total_true_bboxes += sum([gt['pred_class']==c for gt in gts])\n",
    "\n",
    "        detections.sort(reverse=True)\n",
    "\n",
    "        TP = torch.zeros((len(detections)))\n",
    "        FP = torch.zeros((len(detections)))\n",
    "\n",
    "        if total_true_bboxes == 0:\n",
    "            continue\n",
    "\n",
    "        for detection_idx, detection in enumerate(detections):\n",
    "            # Only take out the ground_truths that have the same\n",
    "            # training idx as detection\n",
    "            num_gts = len(truth[detection[1]])\n",
    "\n",
    "            # find most closest g.t box to pred as best_gt_idx\n",
    "            best_iou = 0\n",
    "            for idx, gt in enumerate(truth[detection[1]]):\n",
    "                #print(gt, detection[2])\n",
    "                \n",
    "                iou = get_iou(gt['bbox'], detection[2])\n",
    "\n",
    "                if iou > best_iou:\n",
    "                    best_iou = iou\n",
    "                    best_gt_idx = idx\n",
    "\n",
    "            # if considered found\n",
    "            #try:\n",
    "            #  print(best_iou, truth[detection[1]][best_gt_idx], detection[2])\n",
    "            #except:\n",
    "            #  pass\n",
    "            if best_iou > iou_threshold:\n",
    "                # only detect ground truth detection once\n",
    "                print(len(is_detected))\n",
    "                print(detection[1], best_gt_idx,best_gt_idx)\n",
    "                if is_detected[detection[1]][best_gt_idx] == False:\n",
    "                    # true positive and add this bounding box to seen\n",
    "                    TP[detection_idx] = 1\n",
    "                    is_detected[detection[1]][best_gt_idx] = True\n",
    "                else: # duplicate is FP\n",
    "                    FP[detection_idx] = 1\n",
    "            # if IOU is lower then the detection is a false positive\n",
    "            else:\n",
    "                FP[detection_idx] = 1\n",
    "        \n",
    "        TP_cumsum = torch.cumsum(TP, dim=0)\n",
    "        FP_cumsum = torch.cumsum(FP, dim=0)\n",
    "        #if len(TP)>0 and len(FP)>0:\n",
    "        #  print(TP_cumsum[-1], FP_cumsum[-1])\n",
    "        #print(total_true_bboxes)\n",
    "        recalls = TP_cumsum / (total_true_bboxes + epsilon)  # ratio of detected objects!\n",
    "        precisions = TP_cumsum / (TP_cumsum + FP_cumsum + epsilon)         # ratio of predictions that are true objects!\n",
    "\n",
    "        precisions = torch.cat((torch.tensor([1]), precisions))\n",
    "        recalls = torch.cat((torch.tensor([0]), recalls))\n",
    "        # torch.trapz for numerical integration\n",
    "        #print(precisions, recalls, torch.trapz(precisions, recalls))\n",
    "        average_precisions.append(torch.trapz(precisions, recalls))\n",
    "        #print('----------')\n",
    "    if per_class: \n",
    "        return average_precisions\n",
    "    else:\n",
    "        return sum(average_precisions) / len(average_precisions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236\n",
      "74 0\n",
      "236\n",
      "148 0\n",
      "236\n",
      "173 0\n",
      "236\n",
      "79 7\n",
      "236\n",
      "83 0\n",
      "236\n",
      "137 0\n",
      "236\n",
      "165 0\n",
      "236\n",
      "47 0\n",
      "236\n",
      "42 0\n",
      "236\n",
      "120 0\n",
      "236\n",
      "3 0\n",
      "236\n",
      "204 0\n",
      "236\n",
      "144 1\n",
      "236\n",
      "31 0\n",
      "236\n",
      "108 0\n",
      "236\n",
      "135 0\n",
      "236\n",
      "72 1\n",
      "236\n",
      "100 6\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[116], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m mean_average_precision(pred,truth, per_class\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "Cell \u001b[0;32mIn[115], line 64\u001b[0m, in \u001b[0;36mmean_average_precision\u001b[0;34m(pred, truth, iou_threshold, num_classes, per_class)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(is_detected))\n\u001b[1;32m     63\u001b[0m \u001b[39mprint\u001b[39m(detection[\u001b[39m1\u001b[39m], best_gt_idx)\n\u001b[0;32m---> 64\u001b[0m \u001b[39mif\u001b[39;00m is_detected[detection[\u001b[39m1\u001b[39;49m]][best_gt_idx] \u001b[39m==\u001b[39m \u001b[39mFalse\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[39m# true positive and add this bounding box to seen\u001b[39;00m\n\u001b[1;32m     66\u001b[0m     TP[detection_idx] \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     67\u001b[0m     is_detected[detection[\u001b[39m1\u001b[39m]][best_gt_idx] \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "mean_average_precision(pred,truth, per_class=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
